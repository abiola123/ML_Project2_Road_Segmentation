{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "DataExpansion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V76HrrpdwNcV",
        "outputId": "8619ec65-8066-4256-a874-92a15a7c234c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#drive.flush_and_unmount()\n",
        "\n",
        "!ls ./drive/MyDrive/ML/Projet2_Road_Segmentation/Ressources\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "import scipy.ndimage \n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "def load_image(infilename):\n",
        "    data = mpimg.imread(infilename)\n",
        "    return data\n",
        "\n",
        "def img_float_to_uint8(img):\n",
        "    rimg = img - np.min(img)\n",
        "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
        "    return rimg\n",
        "\n",
        "# Concatenate an image and its groundtruth\n",
        "def concatenate_images(img, gt_img):\n",
        "    nChannels = len(gt_img.shape)\n",
        "    w = gt_img.shape[0]\n",
        "    h = gt_img.shape[1]\n",
        "    if nChannels == 3:\n",
        "        cimg = np.concatenate((img, gt_img), axis=1)\n",
        "    else:\n",
        "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "        gt_img8 = img_float_to_uint8(gt_img)          \n",
        "        gt_img_3c[:,:,0] = gt_img8\n",
        "        gt_img_3c[:,:,1] = gt_img8\n",
        "        gt_img_3c[:,:,2] = gt_img8\n",
        "        img8 = img_float_to_uint8(img)\n",
        "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
        "    return cimg\n",
        "\n",
        "root_dir = \"./drive/MyDrive/ML/Projet2_Road_Segmentation/Ressources/training/\"\n",
        "\n",
        "image_dir = root_dir + \"images/\"\n",
        "files = os.listdir(image_dir)\n",
        "n = len(files)\n",
        "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
        "\n",
        "\n"
      ],
      "id": "V76HrrpdwNcV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "test_set_images  training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "353bf9ed"
      },
      "source": [
        "#First of all we have to chose between offline expansion (expanding our whole dataset beforehand) and online augmentation (expanding mini-batches at each iteration)\n",
        "\n",
        "#We know that online expansion is preferred for relatively large datasets because we can't necessarily handle the explosive increase in size of the dataset\n",
        "#Our initial dataset is really small (only 100 elements). Therefore we can apply offline expansion in order to reach several thousands of inputs\n",
        "\n",
        "\n",
        "#Show image\n",
        "#cimg = concatenate_images(imgs_flipped[99], gt_imgs_flipped[99])\n",
        "#fig1 = plt.figure(figsize=(10, 10))\n",
        "#plt.imshow(cimg, cmap='Greys_r')"
      ],
      "id": "353bf9ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4de44c6b"
      },
      "source": [
        "import cv2\n",
        "\n",
        "def rotate_image(mat, angle):\n",
        "    \"\"\"\n",
        "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
        "    \"\"\"\n",
        "\n",
        "    height, width = mat.shape[:2] # image shape has 3 dimensions\n",
        "    image_center = (width/2, height/2) # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
        "\n",
        "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
        "\n",
        "    # rotation calculates the cos and sin, taking absolutes of those.\n",
        "    abs_cos = abs(rotation_mat[0,0]) \n",
        "    abs_sin = abs(rotation_mat[0,1])\n",
        "\n",
        "    # find the new width and height bounds\n",
        "    bound_w = int(height * abs_sin + width * abs_cos)\n",
        "    bound_h = int(height * abs_cos + width * abs_sin)\n",
        "\n",
        "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
        "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
        "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
        "\n",
        "    # rotate image with the new bounds and translated rotation matrix\n",
        "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
        "    return rotated_mat"
      ],
      "id": "4de44c6b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3483abbb"
      },
      "source": [
        "#1. Flip\n",
        "def flip_images_lr(imgs,gt_imgs):\n",
        "    n = len(imgs)\n",
        "    imgs_flipped = [np.fliplr(imgs[i]) for i in range(n)]\n",
        "    gt_imgs_flipped = [np.fliplr(gt_imgs[i]) for i in range(n)]\n",
        "    return imgs_flipped, gt_imgs_flipped\n",
        "\n",
        "def flip_images_ud(imgs,gt_imgs):\n",
        "    n = len(imgs)\n",
        "    imgs_flipped = [np.flipud(imgs[i]) for i in range(n)]\n",
        "    gt_imgs_flipped = [np.flipud(gt_imgs[i]) for i in range(n)]\n",
        "    return imgs_flipped, gt_imgs_flipped\n",
        "\n",
        "\n",
        "\n",
        "def flip_pipeline(imgs,gt_imgs):\n",
        "    imgs_flipped_lfr, gt_imgs_flipped_lfr = flip_images_lr(imgs,gt_imgs)\n",
        "    imgs_flipped_ud, gt_imgs_flipped_ud = flip_images_ud(imgs,gt_imgs)\n",
        "   \n",
        "    return imgs_flipped_lfr + imgs_flipped_ud,gt_imgs_flipped_lfr+gt_imgs_flipped_ud\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "#flip_pipeline(imgs,gt_imgs) \n"
      ],
      "id": "3483abbb",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "282a6246"
      },
      "source": [
        "#2. Rotate\n",
        "\n",
        "def rotate(imgs,gt_imgs,angle):\n",
        "    n = len(imgs)\n",
        "    imgs_rot = [scipy.ndimage.interpolation.rotate(imgs[i], angle, axes=(1, 0), reshape=False, output=None, order=3, mode='reflect', cval=0.0, prefilter=True) for i in range(n)]\n",
        "    #imgs_rot_resized = [cv2.resize(imgs_rot[i], (400,400), interpolation = 0) for i in range(n)]\n",
        "    gt_imgs_rot = [scipy.ndimage.interpolation.rotate(gt_imgs[i], angle, axes=(1, 0), reshape=False, output=None, order=3, mode='reflect', cval=0.0, prefilter=True) for i in range(n)]\n",
        "    #gt_imgs_rot_resized = [cv2.resize(gt_imgs_rot[i], (400,400), interpolation = 0) for i in range(n)]\n",
        "    return imgs_rot,gt_imgs_rot\n",
        "    \n",
        "\n",
        "    \n",
        "def rotatation_pipeline(imgs,gt_imgs,nb_rotations):\n",
        "    \n",
        "    imgs_output = []\n",
        "    gt_imgs_output = []\n",
        "    stepSize = 360/nb_rotations\n",
        "    angle = stepSize\n",
        "    for i in range(nb_rotations):\n",
        "        imgs_rot_tmp, gt_imgs_rot_tmp = rotate(imgs,gt_imgs,angle)\n",
        "        imgs_output = imgs_output + imgs_rot_tmp\n",
        "        gt_imgs_output = gt_imgs_output + gt_imgs_rot_tmp\n",
        "        angle += stepSize\n",
        "   \n",
        "    return imgs_output,gt_imgs_output\n",
        "    \n",
        "\n",
        "#imgs_rotated, gt_imgs_rotated = rotatation_pipeline(imgs,gt_imgs,8)\n",
        "#print(np.array(imgs_rotated).shape)    \n",
        "#cimg = concatenate_images(imgs_rotated[0],gt_imgs_rotated[0])\n",
        "#fig1 = plt.figure(figsize=(10, 10))\n",
        "#plt.imshow(cimg, cmap='Greys_r')"
      ],
      "id": "282a6246",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ed06d17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69609cb0-cd8f-4212-de90-9f1d66afe8dd"
      },
      "source": [
        "#3. Crop\n",
        "\n",
        "def random_crop_and_resize(image):\n",
        "    width = image.shape[0]\n",
        "    cropped_image = tf.image.random_crop(image, size = [125,125,3])\n",
        "    print(type(image))\n",
        "    cropped_image = tf.image.resize(cropped_image, [400,400])\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "def crop_and_resize_imgs(imgs,gt_imgs):\n",
        "    n = len(imgs)\n",
        "    \n",
        "    gt_imgs = np.array(gt_imgs).reshape((-1,400,400,1)).tolist()\n",
        "   \n",
        "    cropped_imgs = []\n",
        "    cropped_gt_imgs = []\n",
        "    #we extract 5 differents crops for each image\n",
        "    for i in range(100):\n",
        "      image_crop = tf.image.crop_and_resize(imgs, [[0,0,0.5,0.5],[0.5,0,1,0.5],[0.25,0.25,0.75,0.75],[0,0.5,0.5,1],[0.5,0.5,1,1]], [i,i,i,i,i], [400,400], method='bilinear',extrapolation_value=0.0, name=None)\n",
        "      gt_image_crop = tf.image.crop_and_resize(gt_imgs, [[0,0,0.5,0.5],[0.5,0,1,0.5],[0.25,0.25,0.75,0.75],[0,0.5,0.5,1],[0.5,0.5,1,1]], [i,i,i,i,i], [400,400], method='bilinear',extrapolation_value=0.0, name=None)\n",
        "\n",
        "      cropped_imgs.append(image_crop)\n",
        "      cropped_gt_imgs.append(gt_image_crop)\n",
        "\n",
        "      print(i)\n",
        "    \n",
        "    #cropped_imgs = [tf.image.crop_and_resize(imgs, [[0,0,0.5,0.5],[0.5,0,1,0.5],[0.25,0.25,0.75,0.75],[0,0.5,0.5,1],[0.5,0.5,1,1]], [i,i,i,i,i], [400,400], method='bilinear',extrapolation_value=0.0, name=None) for i in range(100)]\n",
        "    #cropped_gt_imgs = [tf.image.crop_and_resize(gt_imgs, [[0,0,0.5,0.5],[0.5,0,1,0.5],[0.25,0.25,0.75,0.75],[0,0.5,0.5,1],[0.5,0.5,1,1]], [i,i,i,i,i], [400,400], method='bilinear',extrapolation_value=0.0, name=None) for i in range(100)]\n",
        "\n",
        "    #we have to adjuste the dimensions\n",
        "    cropped_imgs = np.array(cropped_imgs).reshape((-1,400,400,3))\n",
        "    cropped_gt_imgs = np.array(cropped_gt_imgs).reshape((-1,400,400))\n",
        "    \n",
        "    return cropped_imgs,cropped_gt_imgs\n",
        "\n",
        "start = time.time()\n",
        "#cropped,gt_cropped = crop_and_resize_imgs(imgs,gt_imgs)\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time elapsed:\", (end-start)/60, \" minutes\")\n",
        "\n",
        "#print(cropped.shape)\n",
        "#print(gt_cropped.shape)\n",
        "\n",
        "\n",
        "#cropped = random_crop_and_resize(imgs[0])\n",
        "#cimg = concatenate_images(cropped[4],gt_cropped[4])\n",
        "#fig1 = plt.figure(figsize=(10, 10))\n",
        "#plt.imshow(cimg, cmap='Greys_r')"
      ],
      "id": "0ed06d17",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed: 2.7418136596679685e-07  minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "252fe88c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b7c84c-816f-484b-e61f-56880eed398b"
      },
      "source": [
        "def full_data_expansion_pipeline(imgs,gt_imgs):\n",
        "  # flip vertically and horizontally\n",
        "  \n",
        "  imgs_flipped, gt_imgs_flipped = flip_pipeline(imgs,gt_imgs)\n",
        "\n",
        "  imgs_out = imgs + imgs_flipped\n",
        "  gt_imgs_out = gt_imgs + gt_imgs_flipped\n",
        "\n",
        "  print(np.array(imgs_out).shape)\n",
        "  print(np.array(gt_imgs_out).shape)\n",
        "  print(\"\\n\\n********************* step 1 done *************************\")\n",
        "\n",
        "  #rotate by steps of 45 degress \n",
        "  \n",
        "  imgs_rotated, gt_imgs_rotated = rotatation_pipeline(imgs_out,gt_imgs_out,8)\n",
        "\n",
        "  imgs_out = imgs_rotated\n",
        "  gt_imgs_out = gt_imgs_rotated\n",
        "\n",
        "  print(np.array(imgs_out).shape)\n",
        "  print(np.array(gt_imgs_out).shape)\n",
        "  print(\"\\n\\n********************* step 2 done *************************\")\n",
        "  #extract 5 different crops for each image\n",
        "  #cropped,gt_cropped = crop_and_resize_imgs(imgs_out,gt_imgs_out)\n",
        "\n",
        "  #imgs_out = imgs_out + cropped\n",
        "  #gt_imgs_out = gt_imgs_out + gt_cropped\n",
        "\n",
        "\n",
        "  return imgs_out,gt_imgs_out\n",
        "\n",
        "  print(\"\\n\\n********************* step 3 done *************************\")\n",
        "\n",
        "imgs_out,gt_imgs_out = full_data_expansion_pipeline(imgs,gt_imgs)"
      ],
      "id": "252fe88c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 400, 400, 3)\n",
            "(300, 400, 400)\n",
            "\n",
            "\n",
            "********************* step 1 done *************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cg-uCAVGc__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c69acb3d-ed37-4fa9-a957-b7707981c993"
      },
      "source": [
        "#write files to disk\n",
        "for i in range(len(imgs_out)):\n",
        "  print(i)\n",
        "  cv2.imwrite(i + \".png\",imgs_out[i])"
      ],
      "id": "-cg-uCAVGc__",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1ea2d3f30a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#write files to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imgs_out' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrSVoHkd8hyT"
      },
      "source": [
        ""
      ],
      "id": "KrSVoHkd8hyT",
      "execution_count": null,
      "outputs": []
    }
  ]
}